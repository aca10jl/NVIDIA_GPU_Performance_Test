# 5 Nov 2020
## FP16
103.999ms per iter

## FP32
180.834ms per iter

## TF32
169.951ms per iter

## Matmul
TF32: 58.584ms per iter

FP32: 102.647ms per iter

## Mixed precision
127.074ms per iter

## Data Parallelisation
112.801ms per iter

## Workspace
- Test with the GPU in which has no monitor cables plugged.
- Fan speed is manually set to 100% (full speed).
- GPU temperature is between 33°C and 42°C during the tests.
- Record the best result from three runs (e.g. python fp16.py && python fp16.py && python fp16.py).
- Parameters: batch_size = 32, iteration = 100.
- The PyTorch is compiled from source.
```

Collecting environment information...
PyTorch version: 1.8.0a0+17c5872
Is debug build: False
CUDA used to build PyTorch: 11.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.1 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.18.2

Python version: 3.8 (64-bit runtime)
Is CUDA available: True
CUDA runtime version: Could not collect
GPU models and configuration: 
GPU 0: GeForce RTX 3090
GPU 1: GeForce RTX 3090

Nvidia driver version: 455.32.00
cuDNN version: Probably one of the following:
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_adv_train.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8
/usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudnn_ops_train.so.8
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.19.2
[pip3] torch==1.8.0a0
[pip3] torchvision==0.9.0a0+78159d6
[conda] blas                      1.0                         mkl  
[conda] magma-cuda110             2.5.2                         1    pytorch
[conda] mkl                       2020.2                      256  
[conda] mkl-include               2020.2                      256  
[conda] mkl-service               2.3.0            py38he904b0f_0  
[conda] mkl_fft                   1.2.0            py38h23d657b_0  
[conda] mkl_random                1.1.1            py38h0573a6f_0  
[conda] numpy                     1.19.2           py38h54aff64_0  
[conda] numpy-base                1.19.2           py38hfa32c7d_0  
[conda] torch                     1.8.0a0                  pypi_0    pypi
[conda] torchvision               0.9.0a0+78159d6          pypi_0    pypi